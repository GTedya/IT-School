{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Bv3q_TtJS9Ue-OaANnzub5Io9NhDK5GC",
      "authorship_tag": "ABX9TyN6rDewoCMTIfCcxPHYymWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTedya/IT-School/blob/first_ex/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import re\n",
        "\n",
        "url = 'https://ironau.ru'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "\n",
        "try:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    corpus_directory = \"corpus\"\n",
        "\n",
        "    if not os.path.exists(corpus_directory):\n",
        "        os.makedirs(corpus_directory)\n",
        "\n",
        "    for div in soup.find_all('div', {'class': 'text'}):\n",
        "        filename = os.path.join(corpus_directory, f\"{url.split('//')[1].replace('/', '')}_{len(div.text)}.txt\")\n",
        "        with open(filename, \"w\", encoding='utf-8') as f:\n",
        "            for link in div.find_all('a'):\n",
        "                href = link.get('href')\n",
        "                if href:\n",
        "                    if not href.startswith('https'):\n",
        "                        href = url +\"/\"+ href\n",
        "                    try:\n",
        "                        page = requests.get(href, headers=headers)\n",
        "                        page.raise_for_status()\n",
        "                        page.encoding = page.apparent_encoding\n",
        "                        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "                        filename = os.path.join(corpus_directory, re.sub(r'[^\\w\\-_\\. ]', '', href.replace(url, '').replace('/', '')+'.txt'))\n",
        "                        with open(filename, \"w\", encoding='utf-8') as f:\n",
        "                            f.write(soup.get_text())\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                        print(f\"Error accessing {href}: {e}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error accessing {url}: {e}\")"
      ],
      "metadata": {
        "id": "TUcjXs01py42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caef23fd-2b73-4a7e-c681-49eb7b0a3113"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        }
      ]
    }
  ]
}